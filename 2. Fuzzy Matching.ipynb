{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400073e1-00d5-4ed1-965b-6f07938a96cc",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The following code will analyze the `name` column to consolidate similar words and check for spelling errors.  \n",
    "**TODOS**:  \n",
    "* [X] Hard-coded fuzzy matching\n",
    "* [X] fuzzywuzzy library\n",
    "* [X] comparison of performance\n",
    "* [X] implement into preprocessing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438d5dd0-4f27-453d-97ed-e93657bbfd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "from src.utils import import_dataset, lazy_ldist, cluster_fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b170d3a-263f-4923-9050-910edffd633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = import_dataset()\n",
    "dat = dat['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81065063-713b-4f6b-b207-30a2bfd19ecd",
   "metadata": {},
   "source": [
    "# 0. Quick test - manually implemented recursive levenstein distance\n",
    "Under `src/utils.py`. Future string distance uses `fuzzywuzzy` library\n",
    "```python\n",
    ">>> lazy_ldist('test_insertion', 'test_insertion_extra')\n",
    "6\n",
    ">>> lazy_ldist('test_deletion', 'test')\n",
    "9\n",
    ">>> lazy_ldist('asdf', 'dsdf')\n",
    "1\n",
    ">>> lazy_ldist('test_replacement', 'xesd_replacement')\n",
    "# Should be 2, but takes infinite due insertion. Same happens with actual data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf300e61-308c-48a8-bdcf-338171cf3e92",
   "metadata": {},
   "source": [
    "# 1. Raw method: Identify similar models and assign top model\n",
    "Group similar models together and assumes model with most frequency is the correct model from cluster.\n",
    "1. Create `model_dict` with each model frequency and assign each (model, freq) from as Nodes\n",
    "2. Create one Link for each pair of variables\n",
    "3. Start with each node in its own cluster, and iterate through list of Links, sorted in descending order of fuzz.ratio_score and do clustering.\n",
    "4. Nodes will be added to a cluster when one of their Links have fuzz.ratio above ratio_threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838b4beb-f1a2-46e8-9dac-abe61ce2a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get models as first word from name column and create model_dictionary with frequency. \n",
    "models = dat.apply(lambda x: x.split(' ')[0])\n",
    "\n",
    "model_dict = {}\n",
    "for model in models:\n",
    "    model_dict[model] = model_dict.get(model, 0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54c3d726-461e-4278-8aaa-8b256be2d857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 clusters\n",
      "Variables for correlation threshold 70\n",
      "---------------------------------------\n",
      "1 ford: 51 | CLUSTER: []\n",
      "2 chevrolet: 43 | CLUSTER: [(89, 'chevroelt')]\n",
      "1 plymouth: 31 | CLUSTER: []\n",
      "1 dodge: 28 | CLUSTER: []\n",
      "1 amc: 28 | CLUSTER: []\n",
      "2 toyota: 25 | CLUSTER: [(92, 'toyouta')]\n",
      "1 datsun: 23 | CLUSTER: []\n",
      "1 buick: 17 | CLUSTER: []\n",
      "1 pontiac: 16 | CLUSTER: []\n",
      "2 volkswagen: 15 | CLUSTER: [(95, 'vokswagen')]\n",
      "1 honda: 13 | CLUSTER: []\n",
      "1 mercury: 11 | CLUSTER: []\n",
      "2 mazda: 10 | CLUSTER: [(80, 'maxda')]\n",
      "1 oldsmobile: 10 | CLUSTER: []\n",
      "1 fiat: 8 | CLUSTER: []\n",
      "1 peugeot: 8 | CLUSTER: []\n",
      "1 audi: 7 | CLUSTER: []\n",
      "1 volvo: 6 | CLUSTER: []\n",
      "1 vw: 6 | CLUSTER: []\n",
      "1 chrysler: 6 | CLUSTER: []\n",
      "1 renault: 5 | CLUSTER: []\n",
      "1 subaru: 4 | CLUSTER: []\n",
      "1 opel: 4 | CLUSTER: []\n",
      "1 saab: 4 | CLUSTER: []\n",
      "1 chevy: 3 | CLUSTER: []\n",
      "1 bmw: 2 | CLUSTER: []\n",
      "1 cadillac: 2 | CLUSTER: []\n",
      "2 mercedes-benz: 2 | CLUSTER: [(76, 'mercedes')]\n",
      "1 triumph: 1 | CLUSTER: []\n",
      "1 capri: 1 | CLUSTER: []\n",
      "1 hi: 1 | CLUSTER: []\n",
      "1 nissan: 1 | CLUSTER: []\n"
     ]
    }
   ],
   "source": [
    "cluster_fuzz(model_dict, ratio_threshold=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501bdc5-5e01-4839-b1e8-12ddba180aec",
   "metadata": {},
   "source": [
    "We see that volkswagen & vw, and chevrolet & chevy is not clustered together using levenshtein distance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fcb91c-6d9f-4e1a-acd8-5b42d87ba08d",
   "metadata": {},
   "source": [
    "# 2. Affinity Propogation to identify simiilar models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5475d9c6-e492-4c5c-bf9a-bb1dbbc8a9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - *chevrolet:* chevrolet, chevy, chrysler, chevroelt\n",
      " - *datsun:* datsun, audi, fiat, renault, honda, subaru, nissan\n",
      " - *volkswagen:* volkswagen, oldsmobile, vokswagen\n",
      " - *opel:* ford, dodge, peugeot, opel, volvo\n",
      " - *toyouta:* plymouth, pontiac, toyota, toyouta\n",
      " - *maxda:* saab, mazda, maxda\n",
      " - *capri:* buick, amc, hi, capri, cadillac, triumph\n",
      " - *vw:* bmw, vw\n",
      " - *mercedes:* mercury, mercedes-benz, mercedes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoryjin99/miniconda3/envs/uci_autompg/lib/python3.9/site-packages/sklearn/cluster/_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "    \n",
    "words = list(model_dict.keys()) #So that indexing with a list will work\n",
    "# print(words)\n",
    "lev_similarity = -1*np.array([[fuzz.ratio(w1,w2) for w1 in words] for w2 in words])\n",
    "\n",
    "affprop = AffinityPropagation(affinity=\"euclidean\", max_iter=100, damping=0.5)\n",
    "affprop.fit(lev_similarity)\n",
    "for cluster_id in np.unique(affprop.labels_):\n",
    "    exemplar = words[affprop.cluster_centers_indices_[cluster_id]]\n",
    "    cluster = [words[i] for i in list(np.nonzero(affprop.labels_==cluster_id)[0])]\n",
    "    cluster_str = \", \".join(cluster)\n",
    "    print(\" - *%s:* %s\" % (exemplar, cluster_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668615c-3393-460d-9c50-298f32fff652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
